{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing most common emotions from given messenger conversations\n",
    "The program uses two models to present the most popular emotions which can be detected in conversations.\n",
    "\n",
    "First we have to insert in the first line the name of the json file with the conversation. The instruction how to download such files from facebook is in README. Then just run all the cells step by step. Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below fixes polish signs in json like 'ę', 'ą' etc and saves result in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'piotrek.json'  # Podmień nazwę pliku wejściowego\n",
    "#pewnie nieoptymalnie ale działa XD\n",
    "\n",
    "def fix_polish_characters(input_file, output_file):\n",
    "    with open(input_file, 'rb') as file:\n",
    "        json_data = file.read().decode('utf-8')\n",
    "        decoded_json = json_data.replace(r'\\u00c4\\u0099', 'ę').replace(r'\\u00c5\\u009b','ś').replace(r'\\u00c5\\u0082','ł')\\\n",
    "            .replace(r'\\u00c4\\u0087','ć').replace(r'\\u00c5\\u00bc','ż').replace(r'\\u00c4\\u0085','ą').replace(r'\\u00c3\\u00b3','ó')\\\n",
    "            .replace(r'\\u00c5\\u0084','ń')\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(decoded_json)\n",
    "\n",
    "# Przykład użycia\n",
    "output_file_path = \"fixed_\"+input_file_path  # Podmień nazwę pliku wyjściowego\n",
    "\n",
    "fix_polish_characters(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below reads messages from json and saves then in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Wczytaj plik JSON\n",
    "with open(output_file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    \n",
    "new_file_name = \"data_\" + output_file_path.replace(\".json\", \".txt\")\n",
    "\n",
    "# Otwórz nowy plik tekstowy do zapisu\n",
    "with open(new_file_name, 'w', encoding='utf-8') as output_file:\n",
    "    # Iteruj przez wiadomości i zapisuj zawartość do pliku\n",
    "    for message in data['messages']:\n",
    "        if 'content' in message:\n",
    "            output_file.write(message['content'] + '. ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below uses the first model to translate sentences from polish to english, because the next model needs english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst po angielsku: Fortunately, you're replying quickly. Okay. He didn't reply to me. Okay. Okay. I don't know what it is for XD courier. Okay. I'll be calling. I'll go. I'll go. I'll go. If you want to go like that. Okay. I'm sure. I'm sure. I'm sure. I'm sure. I'm sure. I'm sure. I'll go for it. I'll go for it. I'll go for it. I'll go for it. I'll go for it. I'm sorry. I'm sure. I'm sure. I'm sure. I'm sure.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def translate_polish_to_english(text):\n",
    "    # Ładowanie modelu i tokenizera dla tłumaczenia z polskiego na angielski\n",
    "    model_name = \"Helsinki-NLP/opus-mt-pl-en\"\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenizacja tekstu\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Tłumaczenie\n",
    "    translation = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "with open(new_file_name, 'r',encoding='utf-8') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Przykład użycia\n",
    "# polish_text = \"Przykładowy tekst do przetłumaczenia.\"\n",
    "english_translation = translate_polish_to_english(file_content)\n",
    "print(\"Tekst po angielsku:\", english_translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below uses the second model to find emotions in the conversation and present them as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'approval', 'score': 0.8042270541191101}, {'label': 'caring', 'score': 0.07204558700323105}, {'label': 'optimism', 'score': 0.06316885352134705}, {'label': 'gratitude', 'score': 0.043394383043050766}, {'label': 'realization', 'score': 0.042865291237831116}, {'label': 'relief', 'score': 0.042029306292533875}, {'label': 'neutral', 'score': 0.04092206060886383}, {'label': 'remorse', 'score': 0.025647573173046112}, {'label': 'joy', 'score': 0.025023262947797775}, {'label': 'confusion', 'score': 0.024801533669233322}, {'label': 'disapproval', 'score': 0.024592392146587372}, {'label': 'annoyance', 'score': 0.013317607343196869}, {'label': 'admiration', 'score': 0.01140284352004528}, {'label': 'disappointment', 'score': 0.010581821203231812}, {'label': 'sadness', 'score': 0.010523905977606773}, {'label': 'nervousness', 'score': 0.005780561361461878}, {'label': 'pride', 'score': 0.004807025659829378}, {'label': 'curiosity', 'score': 0.0045570870861411095}, {'label': 'embarrassment', 'score': 0.0032222745940089226}, {'label': 'fear', 'score': 0.003001175355166197}, {'label': 'love', 'score': 0.002952574985101819}, {'label': 'desire', 'score': 0.0027688946574926376}, {'label': 'excitement', 'score': 0.0027372182812541723}, {'label': 'anger', 'score': 0.0022825023625046015}, {'label': 'grief', 'score': 0.0019515992607921362}, {'label': 'amusement', 'score': 0.0013870714465156198}, {'label': 'surprise', 'score': 0.0013130008010193706}, {'label': 'disgust', 'score': 0.0011581965954974294}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "    \n",
    "sentences = [english_translation]\n",
    "\n",
    "model_outputs = classifier(sentences)\n",
    "print(model_outputs[0])\n",
    "# produces a list of dicts for each of the labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
