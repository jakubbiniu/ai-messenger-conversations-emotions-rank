{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing most common emotions from given messenger conversations\n",
    "The program uses two models to present the most popular emotions which can be detected in conversations.\n",
    "\n",
    "First we have to insert in the first line the name of the json file with the conversation. You can download the json files with your messenger conversations from Facebook. Then just run all the cells step by step. Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to install some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jakub\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below fixes polish signs in json like 'ę', 'ą' etc and saves result in a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'file.json'  # filename\n",
    "\n",
    "def fix_polish_characters(input_file, output_file):\n",
    "    with open(input_file, 'rb') as file:\n",
    "        json_data = file.read().decode('utf-8')\n",
    "        decoded_json = json_data.replace(r'\\u00c4\\u0099', 'ę').replace(r'\\u00c5\\u009b','ś').replace(r'\\u00c5\\u0082','ł')\\\n",
    "            .replace(r'\\u00c4\\u0087','ć').replace(r'\\u00c5\\u00bc','ż').replace(r'\\u00c4\\u0085','ą').replace(r'\\u00c3\\u00b3','ó')\\\n",
    "            .replace(r'\\u00c5\\u0084','ń').replace(r'\\u00c5\\u00ba','ź')\n",
    "        \n",
    "        with open(output_file, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(decoded_json)\n",
    " \n",
    "output_file_path = \"fixed_\"+input_file_path  # output filename\n",
    "\n",
    "fix_polish_characters(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below reads messages from json and saves then in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read JSON\n",
    "with open(output_file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    \n",
    "new_file_name = \"data_\" + output_file_path.replace(\".json\", \".txt\")\n",
    "\n",
    "with open(new_file_name, 'w', encoding='utf-8') as output_file:\n",
    "    for message in data['messages']:\n",
    "        if 'content' in message:\n",
    "            output_file.write(message['content'] + '. ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below uses the first model to translate sentences from polish to english, because the next model needs english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekst po angielsku: I'd like to start with that. He's going there. Oh, yeah. I was thinking about the saint maximum I already have. They wouldn't fit on the left wing. Tomorrow I think about Neymar, if Comana, special Mitoma. Video chat ended... The video chat ended... So when you're ready I'm ready. As I ate something. tasty too. I guess it's probably in about 10 minutes. I'll eat and I can be. because today Tuesday. and yes. Because today spaghetti that I do in 15 minutes. But it's okay to eat it.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def translate_polish_to_english(text):\n",
    "    # loading model\n",
    "    model_name = \"Helsinki-NLP/opus-mt-pl-en\"\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenization\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # translating\n",
    "    translation = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "\n",
    "with open(new_file_name, 'r',encoding='utf-8') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "english_translation = translate_polish_to_english(file_content)\n",
    "print(\"Text in English:\", english_translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below uses the second model to find emotions in the conversation and present them as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.6382584571838379}, {'label': 'approval', 'score': 0.40677452087402344}, {'label': 'realization', 'score': 0.04068932682275772}, {'label': 'optimism', 'score': 0.03435012325644493}, {'label': 'desire', 'score': 0.016977740451693535}, {'label': 'excitement', 'score': 0.014631872065365314}, {'label': 'joy', 'score': 0.012363879941403866}, {'label': 'admiration', 'score': 0.0056058987975120544}, {'label': 'confusion', 'score': 0.005055004730820656}, {'label': 'disapproval', 'score': 0.004396679811179638}, {'label': 'annoyance', 'score': 0.004146473947912455}, {'label': 'curiosity', 'score': 0.003435862949118018}, {'label': 'relief', 'score': 0.003081168979406357}, {'label': 'love', 'score': 0.003008962841704488}, {'label': 'disappointment', 'score': 0.0027620592154562473}, {'label': 'caring', 'score': 0.0018294511828571558}, {'label': 'amusement', 'score': 0.0015960148302838206}, {'label': 'surprise', 'score': 0.0014874140033498406}, {'label': 'pride', 'score': 0.0012389018665999174}, {'label': 'sadness', 'score': 0.0008169774082489312}, {'label': 'fear', 'score': 0.0008139314013533294}, {'label': 'nervousness', 'score': 0.000813404971268028}, {'label': 'disgust', 'score': 0.0007774126715958118}, {'label': 'gratitude', 'score': 0.0006466684862971306}, {'label': 'anger', 'score': 0.0004154761554673314}, {'label': 'embarrassment', 'score': 0.00029269393417052925}, {'label': 'grief', 'score': 0.00028485097573138773}, {'label': 'remorse', 'score': 0.00023861201771069318}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "    \n",
    "sentences = [english_translation]\n",
    "\n",
    "model_outputs = classifier(sentences)\n",
    "print(model_outputs[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
